from io import BytesIO
from fastapi.responses import Response
from pydantic import BaseModel
import torch
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler

class PromptDict(BaseModel):
    prompt: str

MODEL_NAME = "stabilityai/stable-diffusion-2"
"""Name of the Hugging Face model that will be used"""

device = "cuda" if torch.cuda.is_available() else "cpu"
"""Device that will process the compute, (cuda = GPU,
or cpu = CPU). Keep in mind that GPU processing tends
to be much more performant. Warning: CUDA drivers only
exist for Windows at this time"""

# Use the Euler scheduler here instead
scheduler = EulerDiscreteScheduler.from_pretrained(MODEL_NAME, subfolder="scheduler")
pipe = StableDiffusionPipeline.from_pretrained(MODEL_NAME, scheduler=scheduler, torch_dtype=torch.float16)
pipe = pipe.to(device)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8085", "https://image-generator.jezzlucena.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
"""CORS middleware, used to accept HTTP requests only from
allowed origins"""

@app.post(
    "/image",
    responses = {
        200: {
            "content": {"image/png": {}}
        }
    },

    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response
)
def text_to_image(data: PromptDict):
    """Returns an image generated based on the provided prompt."""

    image: bytes = pipe(prompt=data.prompt).images[0]
    image_io = BytesIO()
    image.save(image_io, format="PNG")
    return Response(content=image_io.getvalue(), media_type="image/png")
